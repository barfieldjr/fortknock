{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_iV9xrXciDd"
      },
      "source": [
        "Mount drive for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "plRfzaHU2eK0",
        "outputId": "ec471189-39f5-41d3-c31e-642afabf224e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uVrykLjcch4"
      },
      "source": [
        "Check dataset directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5BVWPjVcbeO"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/fort/obj_train_data/images/train\n",
        "!ls /content/drive/MyDrive/fort/obj_train_data/images/val\n",
        "!ls /content/drive/MyDrive/fort/obj_train_data/images/test\n",
        "\n",
        "!cat /content/drive/MyDrive/fort/obj_train_data/dataset.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYVxDFErco6v"
      },
      "source": [
        "Clone YOLOv5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kgKGjZDv2gxG",
        "outputId": "0db6e136-7dc2-499b-b1fb-9731d4740e5b"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TMG0T8LctF6"
      },
      "source": [
        "Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YVUF_kYF2hTu",
        "outputId": "d54dddcf-56e6-42ae-abab-5bf072f1f6c0"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wy79Bf2cyeV"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T31aOKg82pBJ",
        "outputId": "f95e866e-b56c-42cb-bb26-e3bb52f68456"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 60 --data /content/drive/MyDrive/fort/obj_train_data/dataset.yaml --weights yolov5s.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwePzKLFc4EY"
      },
      "source": [
        "Save model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqzb2Y0w2qUY"
      },
      "outputs": [],
      "source": [
        "!cp runs/train/exp/weights/best.pt /content/drive/MyDrive/fort/knockdown_model_weights.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjnTQgsc62Z"
      },
      "source": [
        "Load YOLO model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YfmJcdzdOT8o",
        "outputId": "6751e5b5-483a-4d66-ce4a-7d49b238b2ff"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/fort/knockdown_model_weights.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pztoDUVzdDwJ"
      },
      "source": [
        "Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lxlsJofCPIu6",
        "outputId": "61b8d7e2-698c-435b-caa8-619e5685e3d0"
      },
      "outputs": [],
      "source": [
        "!python val.py --weights /content/drive/MyDrive/fort/knockdown_model_weights.pt --data /content/drive/MyDrive/fort/obj_train_data/dataset.yaml --task test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW9JWSa9QoCV",
        "outputId": "303d04aa-87e8-46f1-adaf-1d623e196cf9"
      },
      "outputs": [],
      "source": [
        "results_base_dir = '/content/yolov5/runs/val/exp'\n",
        "os.listdir(results_base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "WxdIZLZkQvHR",
        "outputId": "614a5236-0bd9-49f3-a5dd-ef11028add27"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from IPython.display import display, Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "test_images_dir = '/content/drive/MyDrive/fort/fortnite_data'\n",
        "\n",
        "test_images = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith('.png') or img.endswith('.jpg')]\n",
        "\n",
        "random_img_path = random.choice(test_images)\n",
        "print(f\"Selected image: {random_img_path}\")\n",
        "\n",
        "# Function to draw bounding boxes with confidence scores\n",
        "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
        "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv1.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)\n",
        "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "# Read the selected image\n",
        "img = cv2.imread(random_img_path)\n",
        "\n",
        "# Resize the image to 640x640\n",
        "img_resized = cv2.resize(img, (640, 640))\n",
        "\n",
        "# Load the trained YOLOv5 model\n",
        "model_path = '/content/drive/MyDrive/fortnite_yolo/knockdown_model_weights.pt'\n",
        "model = torch.hub.load('/content/yolov5', 'custom', path=model_path, source='local')\n",
        "\n",
        "# Adjust model settings\n",
        "model.conf = 0.1  # confidence threshold\n",
        "\n",
        "# Run inference on the resized image\n",
        "print(\"Running inference...\")\n",
        "results = model(img_resized)\n",
        "\n",
        "# Print the results to see the output structure\n",
        "print(results)\n",
        "print(results.xyxy)\n",
        "\n",
        "# Check if there are any detections\n",
        "if results.xyxy[0].shape[0] > 0:\n",
        "    # Extract the confidence scores\n",
        "    confidences = results.xyxy[0][:, 4].cpu().numpy()\n",
        "    print(f\"Confidence scores: {confidences}\")\n",
        "\n",
        "    # Draw bounding boxes with confidence scores\n",
        "    for *box, conf, cls in results.xyxy[0]:\n",
        "        label = f'{model.names[int(cls)]} {conf:.2f}'\n",
        "        plot_one_box(box, img_resized, label=label, color=(255, 0, 0), line_thickness=2)\n",
        "\n",
        "    # Convert the image to RGB\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Save a temporary copy to display\n",
        "    temp_img_path = random_img_path.replace('.png', '_conf_display.png').replace('.jpg', '_conf_display.jpg')\n",
        "    cv2.imwrite(temp_img_path, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    # Display the image\n",
        "    display(Image(filename=temp_img_path))\n",
        "else:\n",
        "    print(\"No detections found in the image.\")\n",
        "\n",
        "# Also display the original resized image\n",
        "img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xEgS-uhqRefe",
        "outputId": "a08fbe4b-c8c3-4b57-8764-b0962f61a452"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Directory where the test results are saved\n",
        "results_dir = '/content/yolov5/runs/val/exp'  # Correct directory based on your output\n",
        "\n",
        "# List of specific result images that might contain predictions\n",
        "result_images = ['val_batch0_pred.jpg', 'val_batch0_labels.jpg']\n",
        "\n",
        "# Function to draw bounding boxes with confidence scores\n",
        "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
        "    # Plots one bounding box on image img\n",
        "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)  # font thickness\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
        "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "# Display each result image\n",
        "for img_name in result_images:\n",
        "    img_path = os.path.join(results_dir, img_name)\n",
        "    if os.path.exists(img_path):\n",
        "        print(f\"Processing image: {img_path}\")  # Print the filename\n",
        "        # Read the image\n",
        "        img = cv2.imread(img_path)\n",
        "        # Run inference\n",
        "        results = model(img_path)\n",
        "\n",
        "        # Draw bounding boxes with confidence scores\n",
        "        for *box, conf, cls in results.xyxy[0]:  # xyxy format\n",
        "            label = f'{model.names[int(cls)]} {conf:.2f}'\n",
        "            plot_one_box(box, img, label=label, color=(255, 0, 0), line_thickness=2)\n",
        "\n",
        "        # Convert the image to RGB (OpenCV uses BGR by default)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Save a temporary copy to display\n",
        "        temp_img_path = img_path.replace('.jpg', '_conf_display.jpg')\n",
        "        cv2.imwrite(temp_img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "        # Display the image using IPython.display\n",
        "        display(Image(filename=temp_img_path))\n",
        "    else:\n",
        "        print(f\"Image not found: {img_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
