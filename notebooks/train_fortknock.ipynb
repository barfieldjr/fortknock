{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive for Google Colab"
      ],
      "metadata": {
        "id": "y_iV9xrXciDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "plRfzaHU2eK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check dataset directory"
      ],
      "metadata": {
        "id": "8uVrykLjcch4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/fort/obj_train_data/images/train\n",
        "!ls /content/drive/MyDrive/fort/obj_train_data/images/val\n",
        "!ls /content/drive/MyDrive/fort/obj_train_data/images/test\n",
        "\n",
        "!cat /content/drive/MyDrive/fort/obj_train_data/dataset.yaml"
      ],
      "metadata": {
        "id": "u5BVWPjVcbeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone YOLOv5"
      ],
      "metadata": {
        "id": "YYVxDFErco6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kgKGjZDv2gxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements"
      ],
      "metadata": {
        "id": "7TMG0T8LctF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YVUF_kYF2hTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "2wy79Bf2cyeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 60 --data /content/drive/MyDrive/fort/obj_train_data/dataset.yaml --weights yolov5s.pt"
      ],
      "metadata": {
        "id": "T31aOKg82pBJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model weights"
      ],
      "metadata": {
        "id": "CwePzKLFc4EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp runs/train/exp/weights/best.pt /content/drive/MyDrive/fort/knockdown_model_weights.pt"
      ],
      "metadata": {
        "id": "mqzb2Y0w2qUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load YOLO model"
      ],
      "metadata": {
        "id": "xpjnTQgsc62Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/fort/knockdown_model_weights.pt')"
      ],
      "metadata": {
        "id": "YfmJcdzdOT8o",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate model"
      ],
      "metadata": {
        "id": "pztoDUVzdDwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights /content/drive/MyDrive/fort/knockdown_model_weights.pt --data /content/drive/MyDrive/fort/obj_train_data/dataset.yaml --task test"
      ],
      "metadata": {
        "id": "lxlsJofCPIu6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_base_dir = '/content/yolov5/runs/val/exp'\n",
        "os.listdir(results_base_dir)"
      ],
      "metadata": {
        "id": "VW9JWSa9QoCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from IPython.display import display, Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "test_images_dir = '/content/drive/MyDrive/fort/fortnite_data'\n",
        "\n",
        "test_images = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith('.png') or img.endswith('.jpg')]\n",
        "\n",
        "random_img_path = random.choice(test_images)\n",
        "print(f\"Selected image: {random_img_path}\")\n",
        "\n",
        "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
        "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv1.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)\n",
        "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "img = cv2.imread(random_img_path)\n",
        "\n",
        "img_resized = cv2.resize(img, (640, 640))\n",
        "\n",
        "model_path = '/content/drive/MyDrive/fortnite_yolo/knockdown_model_weights.pt'\n",
        "model = torch.hub.load('/content/yolov5', 'custom', path=model_path, source='local')\n",
        "\n",
        "model.conf = 0.1\n",
        "\n",
        "print(\"Running inference...\")\n",
        "results = model(img_resized)\n",
        "\n",
        "print(results)\n",
        "print(results.xyxy)\n",
        "\n",
        "if results.xyxy[0].shape[0] > 0:\n",
        "    confidences = results.xyxy[0][:, 4].cpu().numpy()\n",
        "    print(f\"Confidence scores: {confidences}\")\n",
        "\n",
        "    for *box, conf, cls in results.xyxy[0]:\n",
        "        label = f'{model.names[int(cls)]} {conf:.2f}'\n",
        "        plot_one_box(box, img_resized, label=label, color=(255, 0, 0), line_thickness=2)\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    temp_img_path = random_img_path.replace('.png', '_conf_display.png').replace('.jpg', '_conf_display.jpg')\n",
        "    cv2.imwrite(temp_img_path, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    display(Image(filename=temp_img_path))\n",
        "else:\n",
        "    print(\"No detections found in the image.\")\n",
        "\n",
        "img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WxdIZLZkQvHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from IPython.display import display, Image\n",
        "\n",
        "\n",
        "results_dir = '/content/yolov5/runs/val/exp'\n",
        "\n",
        "\n",
        "result_images = ['val_batch0_pred.jpg', 'val_batch0_labels.jpg']\n",
        "\n",
        "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
        "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)\n",
        "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "for img_name in result_images:\n",
        "    img_path = os.path.join(results_dir, img_name)\n",
        "    if os.path.exists(img_path):\n",
        "        print(f\"Processing image: {img_path}\")\n",
        "        img = cv2.imread(img_path)\n",
        "        results = model(img_path)\n",
        "\n",
        "        for *box, conf, cls in results.xyxy[0]:\n",
        "            label = f'{model.names[int(cls)]} {conf:.2f}'\n",
        "            plot_one_box(box, img, label=label, color=(255, 0, 0), line_thickness=2)\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        temp_img_path = img_path.replace('.jpg', '_conf_display.jpg')\n",
        "        cv2.imwrite(temp_img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "        display(Image(filename=temp_img_path))\n",
        "    else:\n",
        "        print(f\"Image not found: {img_path}\")\n"
      ],
      "metadata": {
        "id": "xEgS-uhqRefe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}